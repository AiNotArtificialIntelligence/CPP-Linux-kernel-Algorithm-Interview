# C++

## i++ 和 ++i

1.前面是先赋值再自增，后面是先自增再赋值

```C++
int i = 3;
//int a = ++ i; 先执行i += 1再赋值，a是4，i是4
int b = i ++;//先赋值，再自加，b是3，i是4
```

2.for循环中的++和--，使用前缀后缀的差异在于执行速度。对于内置类型，如int等，采用哪种格式不会有差别，但对于用户定义的且有用户定义的递增和递减操作符的类型，前缀格式的效率更高，，，，，，前缀直接将值加1，然后返回结果。但是后缀版本首先复制一个拷贝，将其加1，然后再将复制的拷贝返回

i++由于是在使用当前值之后再+1，所以需要一个临时的变量来转存。而++i则是在直接+1，省去了对内存的操作的环节，相对而言能够提高性能

对于自定义类型，在类里使用的时候，++i的效率更高

在没有编译器优化的情况下，++i更好。优化过后两者都一样，看起来似乎喜欢怎样写都无所谓了

3.**i++ 不能作为左值，而++i 可以。**

左值是对应内存中有确定存储地址的对象的表达式的值，而右值是所有不是左值的表达式的值。一般来说，左值是可以放到赋值符号左边的变量。

但能否被赋值不是区分左值与右值的依据。比如，C++的const左值是不可赋值的；而作为临时对象的右值可能允许被赋值。左值与右值的根本区别在于是否允许取地址&运算符获得对应的内存地址。

```C++
int i = 0;
int *p1 = &（++i）；//正确
int *p2 = &（i++）；//错误
++i = 1；//正确
i++ = 1；//错误
```

## C++的内存管理

C++ 的内存分区主要有：代码区、未初始化数据区（BSS）、已初始化数据区（DATA）、栈区（Stack）、堆区（Heap）

\1. 代码区

加载的是可执行文件代码段，所有的可执行代码都加载到代码区，这块内存是不可以在运行期间修改的。

\2. 未初始化数据区

加载的是可执行文件BSS 段，位置可以分开也可以紧靠数据段，存储于数据段的数据（全局未初始化，静态未初始化数据）的生存周期为整个程序运行过程。

\3. 已初始化数据区（全局初始化数据区/静态数据区）

加载的是可执行文件数据段，存储于数据段（全局初始化，静态初始化数据，文字常量(只读)）的数据的生存周期为整个程序运行过程。

\4. 栈区

栈是一种先进后出的内存结构，由编译器自动分配释放，存放函数的参数值、返回值、局部变量等。在程序运行过程中实时加载和释放，因此，局部变量的生存周期为申请到释放该段栈空间。

\5. 堆区

堆是一个大容器，它的容量要远远大于栈，但没有栈那样先进后出的顺序，用于动态内存分配。堆在内存中位于BSS区和栈区之间。一般由程序员分配和释放，若程序员不释放，程序结束时由操作系统回收。

## static关键字的作用

\1. 全局静态变量

在全局变量前加上关键字static，全局变量就定义成一个全局静态变量.

静态存储区，在整个程序运行期间一直存在。

初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）；

作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。

\2.  局部静态变量

在局部变量之前加上关键字static，局部变量就成为一个局部静态变量。

内存中的位置：静态存储区

初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）；

作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变；

\3. 静态函数

在函数返回类型前加static，函数就定义为静态函数。函数的定义和声明在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。

函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突；

warning：不要再头文件中声明static的全局函数，不要在cpp内声明非static的全局函数，如果你要在多个cpp中复用该函数，就把它的声明提到头文件里去，否则cpp内部声明需加上static修饰；

\4. 类的静态成员

在类中，静态成员可以实现多个对象之间的数据共享，并且使用静态数据成员还不会破坏隐藏的原则，即保证了安全性。因此，静态成员是类的所有对象中共享的成员，而不是某个对象的成员。对多个对象来说，静态数据成员只存储一处，供所有对象共用

\5. 类的静态函数

静态成员函数和静态数据成员一样，它们都属于类的静态成员，它们都不是对象成员。因此，对静态成员的引用不需要用对象名。

在静态成员函数的实现中不能直接引用类中说明的非静态成员，可以引用类中说明的静态成员（这点非常重要）。如果静态成员函数中要引用非静态成员时，可通过对象来引用。从中可看出，调用静态成员函数使用如下格式：<类名>::<静态成员函数名>(<参数表>);



加了static关键字的全局变量只能在本文件中使用。例如在a.c中定义了static int a=10;那么在b.c中用extern int a是拿不到a的值的，a的作用域只在a.c中。 2.static定义的静态局部变量分配在数据段上，普通的局部变量分配在栈上，会因为函数栈帧的释放而被释放掉。
\3. 对一个类中成员变量和成员函数来说，加了static关键字，则此变量/函数就没有了this指针了，必须通过类名才能访问

## C与C++的区别

1.C面向过程，CPP面向对象，，，因此CPP中有类、对象、继承、多态、、、，此外，CPP支持模板、运算符重载、异常处理机制，以及一个强大的C++标准模板库STL

2.动态内存管理

C使用malloc和free进行堆内存分配和释放，CPP使用new、free进行自由存储区内存管理

3.CPP支持带有默认值的函数，，函数重载、inline内联函数

4CPP支持引用

5.C++相比于C，增加了许多类型安全的功能，比如强制类型转换

6.CPP支持范式编程，比如模板类、函数模板等

## malloc/new与free/delete

1.malloc动态分配堆的内存，new是自由存储区，，但是一般都使用malloc来实现new，所以就和使用堆一样（想不想linux使用的内存管理机制，虽然支持段，但是段起始地址都为0，和只有页式管理一样）

2.malloc只分配开辟内存，但是不初始化，只能用户自己初始化，，new不但可以开辟内存，还可以初始化，，比如

```C++
int a = new int(10);
```

3.malloc是函数，开辟内存需要传入字节数，返回void*，表示分配的内存的起始地址，因此，malloc函数返回的类型需要强制转换成所需类型的指针，，，，new是操作符，开辟内存需要指定类型，返回指定类型的地址，不需要强制转换，，，，还可以进行重载

4..malloc开辟内存失败返回NULL，而new分配失败是抛出bad_alloc类型的异常

5.delete比free多一项功能，delete在释放内存之前，还可以析构指针指向的对象

## C++中的四种cast转换

C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast

1、const_cast

用于将const变量转为非const

2、static_cast

用于各种隐式转换，比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知；

3、dynamic_cast

用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。

向上转换：指的是子类向基类的转换

向下转换：指的是基类向子类的转换

它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。

4、reinterpret_cast

几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用；

为什么不使用C的强制转换？C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错

## 请说一下C/C++ 中指针和引用的区别？

1.指针有自己的一块空间，而引用只是一个别名；

2.使用sizeof看一个指针的大小是4，而引用则是被引用对象的大小；

3.指针可以被初始化为NULL，而引用必须被初始化且必须是一个已有对象 的引用；

4.作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引 用的修改都会改变引用所指向的对象；

5.可以有const指针，但是没有const引用；

6.指针在使用中可以指向其它对象，但是引用只能是一个对象的引用，不能 被改变；

7.指针可以有多级指针（**p），而引用只有一级；

8.指针和引用使用++运算符的意义不一样；

9.如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露。

## 智能指针————>参见八股那本书吧

## 野指针和悬空指针

1. 野指针（Wild Pointer）：没有初始化的指针。

2. 悬空指针（Dangling Pointer）：指向的内存已经释放。

   由于指向的是不安全不可控的区域，任何情况都有可能发生，比如：崩溃、执行结果错误、系统崩溃等。

   传统方法：每一个指针必须初始化为 null，可以避免 [野指针](https://so.csdn.net/so/search?q=野指针&spm=1001.2101.3001.7020) 的产生。但是对于悬空指针来说就比较难处理，只能每次 delete 内存之后将指针置为 null，但是其他指向该内存的指针如果有遗漏没有置为 null 的则很容易造成悬空指针。现代方法：使用智能指针

## 智能指针内存泄漏

当两个对象相互使用一个shared_ptr成员变量指向对方，会造成循环引用，使引用计数失效，从而导致内存泄漏。例如：parent有一个shared_ptr类型的成员指向孩子，而child也有一个shared_ptr类型的成员指向父亲。然后在创建孩子和父亲对象时也使用了智能指针c和p，随后将c和p分别又赋值给child的智能指针成员parent和parent的智能指针成员child。从而形成了一个循环引用

## 请你来说一下智能指针的内存泄漏如何解决

为了解决循环引用导致的内存泄漏，引入了weak_ptr弱指针，weak_ptr的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，其类似一个普通指针，但不指向引用计数的共享内存，但是其可以检测到所管理的对象是否已经被释放，从而避免非法访问。

## 请你回答一下为什么析构函数必须是虚函数？为什么C++默认的析构函数不是虚函数

将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，防止内存泄漏。



C++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。

## 请你来说一下函数指针

1、定义

函数指针是指向函数的指针变量。

函数指针本身首先是一个指针变量，该指针变量指向一个具体的函数。这正如用指针变量可指向整型变量、字符型、数组一样，这里是指向函数。

C在编译时，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。有了指向函数的指针变量后，可用该指针变量调用函数，就如同用指针变量可引用其他类型变量一样，在这些概念上是大体一致的。

2、用途：

调用函数和做函数的参数，比如回调函数。

3、示例：

```C++
char * fun(char * p)  {…}    // 函数fun
char * (*pf)(char * p);       // 函数指针pf
pf = fun;            // 函数指针pf指向函数fun
pf(p);            // 通过函数指针pf调用函数fun
```

## 请你来说一下fork函数

Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

\#include <sys/types.h>

\#include <unistd.h>

pid_t fork(void);

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

## 请你来说一下C++中析构函数的作用

析构函数与构造函数对应，当对象结束其生命周期，如对象所在的函数已调用完毕时，系统会自动执行析构函数。

析构函数名也应与类名相同，只是在函数名前面加一个位取反符~，例如~stud( )，以区别于构造函数。它不能带任何参数，也没有返回值（包括void类型）。只能有一个析构函数，不能重载。

如果用户没有编写析构函数，编译系统会自动生成一个缺省的析构函数（即使自定义了析构函数，编译器也总是会为我们合成一个析构函数，并且如果自定义了析构函数，编译器在执行时会先调用自定义的析构函数再调用合成的析构函数），它也不进行任何操作。所以许多简单的类中没有用显式的析构函数。

如果一个类中有指针，且在使用的过程中动态的申请了内存，那么最好显示构造析构函数在销毁类之前，释放掉申请的内存空间，避免内存泄漏。

类析构顺序：**1）派生类本身的析构函数；2）对象成员析构函数；3）基类析构函数。**与构造函数顺序相反

## 请你来说一下静态函数和虚函数的区别

静态函数在编译的时候就已经确定运行时机，虚函数在运行的时候动态绑定。虚函数因为用了虚函数表机制，调用的时候会增加一次内存开销

##  请你来说一说重载和覆盖

重载：两个函数名相同，但是参数列表不同（个数，类型），返回值类型没有要求，在同一作用域中
重写：子类继承了父类，父类中的函数是虚函数，在子类中重新定义了这个虚函数，这种情况是重写

## 请你说一说你理解的虚函数和多态

多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，**在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数**。
虚函数的实现：**在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址**。使用了虚函数，会增加访问内存开销，降低效率。

## 请你来写个函数在main函数执行前先运行

全局static变量的初始化在程序初始阶段，先于main函数的执行，所以可以利用这一点。在leetcode里经常见到利用一点，在main之前关闭cin与stdin的同步来“加快”速度的黑科技

```C++
static int _ = [] {
    cin.sync_with_stdio(false);
    return 0;
}();
```

`__attribute((constructor))`是gcc扩展，标记这个函数应当在main函数之前执行。同样有一个`__attribute((destructor))`，标记函数应当在程序结束之前（main结束之后，或者调用了exit后）执行

## 请你来说一下智能指针shared_ptr的实现

核心要理解引用计数，什么时候销毁底层指针，还有赋值，拷贝构造时候的引用计数的变化，析构的时候要判断底层指针的引用计数为0了才能真正释放底层指针的内存

https://cloud.tencent.com/developer/article/1688444有关智能指针

## 以下四行代码的区别是什么？ const char * arr = "123"; char * brr = "123"; const char crr[] = "123"; char drr[] = "123";

```C++
const char * arr = "123";//字符串123保存在常量区，const本来是修饰arr指向的值不能通过arr去修改，但是字符串“123”在常量区，本来就不能改变，所以加不加const效果都一样
char * brr = "123";//字符串123保存在常量区，这个arr指针指向的是同一个位置，同样不能通过brr去修改"123"的值
const char crr[] = "123";//这里123本来是在栈上的，但是编译器可能会做某些优化，将其放到常量区，，这种形式会复制一份字符串常量到栈区
char drr[] = "123";//字符串123保存在栈区，可以通过drr去修改
```

## c++ 顶层（top-level）const 和底层（low-level）const

```C++
//顶层const 指的是指针本身是一个常量，底层const指的事指针所指的对象是一个常量。
int i=0；
int* const p1=&i;  //不能改变p1的值，这是一个顶层const
const int ci=42;     //不能改变ci的值，这是一个顶层const
const int *p2=&ci;  //不能改变p2的值，这是一个底层const
const int* const p3=p2；//靠右的const是顶层const，靠左的const是一个底层const
const int &r=ci；//用于声明引用的const，都是底层const
```

## 请你来说一下C++里是怎么定义常量的？常量存放在内存的哪个位置？

常量在C++里的定义就是一个top-level const加上对象类型，常量定义必须初始化。对于局部对象，常量存放在栈区，对于全局对象，常量存放在全局/静态存储区。对于字面值常量，常量存放在常量存储区。

## 请你来回答一下const修饰成员函数的目的是什么？

const修饰的成员函数表明函数调用不会对对象做出任何更改，事实上，如果确认不会对对象做更改，就应该为函数加上const限定，这样无论const对象还是普通对象都可以调用该函数。

## 请你来说一说隐式类型转换

首先，对于内置类型，低精度的变量给高精度变量赋值会发生隐式类型转换，其次，对于只存在单个参数的构造函数的对象构造来说，函数调用可以直接使用该参数传入，编译器会自动调用其构造函数生成临时对象。

## 请你来说一说C++函数栈空间的最大值

默认是1M，不过可以调整

## 请你来说一说extern“C”

extern "C" 既可以修饰一句 C++ 代码，也可以修饰一段 C++ 代码，它的功能是让编译器以处理 C 语言代码的方式来处理修饰的 C++ 代码。    

C++调用C函数需要extern C，因为C语言没有函数重载。

## 请你说说你了解的RTTI

运行时类型检查，在C++层面主要体现在dynamic_cast和typeid,VS中虚函数表的-1位置存放了指向type_info的指针。对于存在虚函数的类型，typeid和dynamic_cast都会去查询type_info

## 请你说说虚函数表具体是怎样实现运行时多态的?

子类若重写父类虚函数，虚函数表中，该函数的地址会被替换，对于存在虚函数的类的对象，在VS中，对象的对象模型的头部存放指向虚函数表的指针，通过该机制实现多态。

## 请你说说C语言是怎么进行函数调用的？

每一个函数调用都会分配函数栈，在栈内进行函数执行过程。调用前，先把返回地址压栈，然后把当前函数的esp指针压栈。

## 请你说说C语言参数压栈顺序？

***从右到左***

## 请你说说C++如何处理返回值？

生成一个临时变量，把它的引用作为函数参数传入函数内。

## 请你回答一下C++中拷贝赋值函数的形参能否进行值传递？

**可以。但是调用拷贝赋值函数的时候，首先要将实参传递给形参，此时会多调用一次拷贝构造，并不会无限递归。**牛客答案说的是不能，应该有点问题，如果是拷贝构造函数的话，是不能的，会无限递归

## 请你说一说select

select()用来确定一个或多个套接字的状态（更为本质一点来讲是文件描述符的状态）。
使用select()所需要包含的头文件是：`#include<sys/select.h>`

select在使用前，先将需要监控的描述符对应的bit位置1，然后将其传给select,当有任何一个事件发生时，select将会返回所有的描述符，需要在应用程序自己遍历去检查哪个描述符上有事件发生，效率很低，并且其不断在内核态和用户态进行描述符的拷贝，开销很大

## 请你说说fork,wait,exec函数

父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写实拷贝机制分配内存，exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。fork从父进程返回子进程的pid，从子进程返回0.调用了wait的父进程将会发生阻塞，直到有子进程状态改变,执行成功返回0，错误返回-1。exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回-1

## 请你来说一下map和set有什么区别，分别又是怎么实现的？

map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree）。由于 map 和set所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和set的操作行为，都只是转调 RB-tree 的操作行为。

map和set区别在于：

（1）map中的元素是key-value（关键字—值）对：关键字起到索引的作用，值则表示与索引相关联的数据；Set与之相对就是关键字的简单集合，set中每个元素只包含一个关键字。

（2）set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key。其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。

（3）map支持下标操作，set不支持下标操作。map可以用key做下标，map的下标运算符[ ]将关键码作为下标去执行查找，如果关键码不存在，则插入一个具有该关键码和mapped_type类型默认值的元素至map中，因此下标运算符[ ]在map应用中需要慎用，const_map不能用，只希望确定某一个关键值是否存在而不希望插入元素时也不应该使用，mapped_type类型没有默认值也不应该使用。如果find能解决需要，尽可能用find。

## 请你来介绍一下STL的allocaotr

STL的分配器用于封装STL容器在内存管理上的底层细节。在C++中，其内存配置和释放如下：

new运算分两个阶段：(1)调用::operator new配置内存;(2)调用对象构造函数构造对象内容

delete运算分两个阶段：(1)调用对象析构函数；(2)调用::operator delete释放内存

为了精密分工，STL allocator将两个阶段操作区分开来：内存配置有alloc::allocate()负责，内存释放由alloc::deallocate()负责；对象构造由::construct()负责，对象析构由::destroy()负责。

同时为了提升内存管理的效率，减少申请小内存造成的内存碎片问题，SGI STL采用了两级配置器，当分配的空间大小超过128B时，会使用第一级空间配置器；当分配的空间大小小于128B时，将使用第二级空间配置器。第一级空间配置器直接使用malloc()、realloc()、free()函数进行内存空间的分配和释放，而第二级空间配置器采用了内存池技术，通过空闲链表来管理内存。

## 请你来说一说STL迭代器删除元素

这个主要考察的是迭代器失效的问题。1.对于序列容器vector,deque来说，使用erase(itertor)后，后边的每个元素的迭代器都会失效，但是后边每个元素都会往前移动一个位置，但是erase会返回下一个有效的迭代器；2.对于关联容器map set来说，使用了erase(iterator)后，当前元素的迭代器失效，但是其结构是红黑树，删除当前元素的，不会影响到下一个元素的迭代器，所以在调用erase之前，记录下一个元素的迭代器即可。3.对于list来说，它使用了不连续分配的内存，并且它的erase方法也会返回下一个有效的iterator，因此上面两种正确的方法都可以使用。

## 请你讲讲STL有什么基本组成

STL主要由以下几部分组成：
容器、迭代器、仿函数、算法、分配器、配接器
他们之间的关系：分配器给容器分配存储空间，算法通过迭代器获取容器中的内容，仿函数可以协助算法完成各种操作，配接器用来套接适配仿函数

## 请你说说STL中map与multimap

1、Map映射，map 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。

底层实现：红黑树

适用场景：有序键值对不重复映射

2、Multimap

多重映射。multimap 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。允许键值重复。

底层实现：红黑树

适用场景：有序键值对可重复映射

## 请你说一说vector和list的区别，应用，越详细越好

1、概念：

1）Vector

连续存储的容器，动态数组，在堆上分配空间

底层实现：数组

两倍容量增长：

vector 增加（插入）新元素时，如果未超过当时的容量，则还有剩余空间，那么直接添加到最后（插入指定位置），然后调整迭代器。

如果没有剩余空间了，则会重新配置原有元素个数的两倍空间，然后将原空间元素通过复制的方式初始化新空间，再向新空间增加元素，最后析构并释放原空间，之前的迭代器会失效。

性能：

访问：O(1)

插入：在最后插入（空间够）：很快

在最后插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。

在中间插入（空间够）：内存拷贝

在中间插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。

删除：在最后删除：很快

在中间删除：内存拷贝

适用场景：经常随机访问，且不经常对非尾节点进行插入删除。

2、List

动态链表，在堆上分配空间，每插入一个元数都会分配空间，每删除一个元素都会释放空间。

底层：双向链表

性能：

访问：随机访问性能很差，只能快速访问头尾节点。

插入：很快，一般是常数开销

删除：很快，一般是常数开销

适用场景：经常插入删除大量数据

2、区别：

1）vector底层实现是数组；list是双向 链表。

2）vector支持随机访问，list不支持。

3）vector是顺序内存，list不是。

4）vector在中间节点进行插入删除会导致内存拷贝，list不会。

5）vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。

6）vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。

3、应用

vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随即访问，而不在乎插入和删除的效率，使用vector。

list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。

## 请你来说一下STL中迭代器的作用，有指针为何还要迭代器

1、迭代器

Iterator（迭代器）模式又称Cursor（游标）模式，用于提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。或者这样说可能更容易理解：Iterator模式是运用于聚合对象的一种模式，通过运用该模式，使得我们可以在不知道对象内部表示的情况下，按照一定顺序（由iterator提供的方法）访问聚合对象中的各个元素。

由于Iterator模式的以上特性：与聚合对象耦合，在一定程度上限制了它的广泛运用，一般仅用于底层聚合支持类，如STL的list、vector、stack等容器类及ostream_iterator等扩展iterator。

2、迭代器和指针的区别

迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，通过重载了指针的一些操作符，->、*、++、--等。迭代器封装了指针，是一个“可遍历STL（ Standard Template Library）容器内全部或部分元素”的对象， 本质是封装了原生指针，是指针概念的一种提升（lift），提供了比指针更高级的行为，相当于一种智能指针，他可以根据不同类型的数据结构来实现不同的++，--等操作。

迭代器返回的是对象引用而不是对象的值，所以cout只能输出迭代器使用*取值后的值而不能直接输出其自身。

3、迭代器产生原因

Iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。

## 请你说一说epoll原理

调用顺序：

```C++
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);
```

首先创建一个epoll对象，然后使用epoll_ctl对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以epoll_event结构体的形式组成一颗红黑树，接着阻塞在epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表。

## 请你回答一下STL里resize和reserve的区别

resize()：改变当前容器内含有元素的数量(size())，eg: vector<int>v; v.resize(len);v的size变为len,如果原来v的size小于len，那么容器新增（len-size）个元素，元素的值为默认为0.当v.push_back(3);之后，则是3是放在了v的末尾，即下标为len，此时容器是size为len+1；
reserve()：改变当前容器的最大容量（capacity）,它不会生成元素，只是确定这个容器允许放入多少对象，如果reserve(len)的值大于当前的capacity()，那么会重新分配一块能存len个对象的空间，然后把之前v.size()个对象通过copy construtor复制过来，销毁之前的内存；

## 请你来说一下C++中类成员的访问权限

C++通过 public、protected、private 三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。在类的内部（定义类的代码内部），无论成员被声明为 public、protected 还是 private，都是可以互相访问的，没有访问权限的限制。在类的外部（定义类的代码之外），只能通过对象访问成员，并且通过对象只能访问 public 属性的成员，不能访问 private、protected 属性的成员

**1.public继承：**基类public成员，protected成员，private成员的访问属性在派生类中分别变成：public, protected, private

**2.protected继承：**基类public成员，protected成员，private成员的访问属性在派生类中分别变成：protected, protected, private

**3.private继承：**基类public成员，protected成员，private成员的访问属性在派生类中分别变成：private, private, private

## 请你来说一下C++中struct和class的区别

在C++中，可以用struct和class定义类，都可以继承。区别在于：structural的默认继承权限和默认访问权限是public，而class的默认继承权限和默认访问权限是private。

另外，class还可以定义模板类形参，比如template <class T, int i>。

## 请你回答一下C++类内可以定义引用数据成员吗？

c++类内可以定义引用成员变量，但要遵循以下三个规则：
1、不能用默认构造函数初始化，必须提供构造函数来初始化引用成员变量。否则会造成引用未初始化错误。
2、构造函数的形参也必须是引用类型
3、不能在构造函数里初始化，必须在初始化列表中进行初始化。

构造函数分为初始化和计算两个阶段，前者对应成员初始化列表，后者对应构造函数函数体。引用必须在初始化阶段，也即在成员初始化链表中完成，否则编译时会报错（引用未初始化）。

## 请你回答一下什么是右值引用，跟左值又有什么区别？

右值引用是C++11中引入的新特性 , 它实现了转移语义和精确传递。它的主要目的有两个方面：

\1. 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。

\2. 能够更简洁明确地定义泛型函数。



左值和右值的概念：

左值：能对表达式取地址、或具名对象/变量。一般指表达式结束后依然存在的持久对象。

右值：不能对表达式取地址，或匿名对象。一般指表达式结束就不再存在的临时对象。



右值引用和左值引用的区别：

\1. 左值可以寻址，而右值不可以。

\2. 左值可以被赋值，右值不可以被赋值，可以用来给左值赋值。

\3. 左值可变,右值不可变（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）。

## 请你来回答一下include头文件的顺序以及双引号””和尖括号<>的区别？

Include头文件的顺序：对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h。那么要在a.c文件中引用b.h文件，并且要先引用b.h，后引用a.h,否则汇报变量类型未声明错误。

双引号和尖括号的区别：编译器预处理阶段查找头文件的路径不一样。

对于使用双引号包含的头文件，查找头文件路径的顺序为：

当前头文件目录

编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）

系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径

对于使用尖括号包含的头文件，查找头文件的路径顺序为：

编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）

系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径

## 请你回答一下malloc的原理，另外brk系统调用和mmap系统调用的作用分别是什么？

Malloc函数用于动态分配内存。为了减少内存碎片和系统调用的开销，malloc其采用内存池的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。

当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。

Malloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。

##  请你回答一下如何判断内存泄漏？

内存泄漏通常是由于调用了malloc/new等内存申请的操作，但是缺少了对应的free/delete。为了判断内存是否泄露，我们一方面可以使用linux环境下的内存泄漏检查工具Valgrind,另一方面我们在写代码时可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否泄露。

## 请你来说一下什么时候会发生段错误

段错误通常发生在访问非法内存地址的时候，具体来说分为以下几种情况：

使用野指针

试图修改字符串常量的内容

## 请你来回答一下什么是memory leak，也就是内存泄漏

内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。

内存泄漏的分类：

\1. 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak.

\2. 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。

\3. 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

## 请你来说一下共享内存相关api

Linux允许不同进程访问同一个逻辑内存，提供了一组API，头文件在sys/shm.h中。

1）新建共享内存shmget

int shmget(key_t key,size_t size,int shmflg);

key：共享内存键值，可以理解为共享内存的唯一性标记。

size：共享内存大小

shmflag：创建进程和其他进程的读写权限标识。

返回值：相应的共享内存标识符，失败返回-1

2）连接共享内存到当前进程的地址空间shmat

void *shmat(int shm_id,const void *shm_addr,int shmflg);

shm_id：共享内存标识符

shm_addr：指定共享内存连接到当前进程的地址，通常为0，表示由系统来选择。

shmflg：标志位

返回值：指向共享内存第一个字节的指针，失败返回-1

3）当前进程分离共享内存shmdt

int shmdt(const void *shmaddr);

4）控制共享内存shmctl

和信号量的semctl函数类似，控制共享内存

int shmctl(int shm_id,int command,struct shmid_ds *buf);

shm_id：共享内存标识符

command: 有三个值

IPC_STAT:获取共享内存的状态，把共享内存的shmid_ds结构复制到buf中。

IPC_SET:设置共享内存的状态，把buf复制到共享内存的shmid_ds结构。

IPC_RMID:删除共享内存

buf：共享内存管理结构体。

## 请你来说一下reactor模型组成

reactor模型要求主线程只负责监听文件描述上是否有事件发生，有的话就立即将该事件通知工作线程，除此之外，主线程不做任何其他实质性的工作，读写数据、接受新的连接以及处理客户请求均在工作线程中完成。其模型组成如下：

![img](https://uploadfiles.nowcoder.com/images/20190313/311436_1552468262115_CB656C4BF3B7635BECB0F5D128C95303)

1）Handle：即操作系统中的句柄，是对资源在操作系统层面上的一种抽象，它可以是打开的文件、一个连接(Socket)、Timer等。由于Reactor模式一般使用在网络编程中，因而这里一般指Socket Handle，即一个网络连接。

2）Synchronous Event Demultiplexer（同步事件复用器）：阻塞等待一系列的Handle中的事件到来，如果阻塞等待返回，即表示在返回的Handle中可以不阻塞的执行返回的事件类型。这个模块一般使用操作系统的select来实现。

3）Initiation Dispatcher：用于管理Event Handler，即EventHandler的容器，用以注册、移除EventHandler等；另外，它还作为Reactor模式的入口调用Synchronous Event Demultiplexer的select方法以阻塞等待事件返回，当阻塞等待返回时，根据事件发生的Handle将其分发给对应的Event Handler处理，即回调EventHandler中的handle_event()方法。

4）Event Handler：定义事件处理方法：handle_event()，以供InitiationDispatcher回调使用。

5）Concrete Event Handler：事件EventHandler接口，实现特定事件处理逻辑。

## 请自己设计一下如何采用单线程的方式处理高并发

在单线程模型中，可以采用I/O复用来提高单线程处理多个请求的能力，然后再采用事件驱动模型，基于异步回调来处理事件来

## 请你说一说C++ STL 的内存优化

1）二级配置器结构
STL内存管理使用二级内存配置器。
1、第一级配置器
第一级配置器以malloc()，free()，realloc()等C函数执行实际的内存配置、释放、重新配置等操作，并且能在内存需求不被满足的时候，调用一个指定的函数。
一级空间配置器分配的是大于128字节的空间
如果分配不成功，调用句柄释放一部分内存
如果还不能分配成功，抛出异常
2、第二级配置器
在STL的第二级配置器中多了一些机制，避免太多小区块造成的内存碎片，小额区块带来的不仅是内存碎片，配置时还有额外的负担。区块越小，额外负担所占比例就越大。
3、分配原则
如果要分配的区块大于128bytes，则移交给第一级配置器处理。
如果要分配的区块小于128bytes，则以内存池管理（memory pool），又称之次层配置（sub-allocation）：每次配置一大块内存，并维护对应的16个空闲链表（free-list）。下次若有相同大小的内存需求，则直接从free-list中取。如果有小额区块被释放，则由配置器回收到free-list中。
当用户申请的空间小于128字节时，将字节数扩展到8的倍数，然后在自由链表中查找对应大小的子链表
如果在自由链表查找不到或者块数不够，则向内存池进行申请，一般一次申请20块
如果内存池空间足够，则取出内存
如果不够分配20块，则分配最多的块数给自由链表，并且更新每次申请的块数
如果一块都无法提供，则把剩余的内存挂到自由链表，然后向系统heap申请空间，如果申请失败，则看看自由链表还有没有可用的块，如果也没有，则最后调用一级空间配置器
2）二级内存池
二级内存池采用了16个空闲链表，这里的16个空闲链表分别管理大小为8、16、24......120、128的数据块。这里空闲链表节点的设计十分巧妙，这里用了一个联合体既可以表示下一个空闲数据块（存在于空闲链表中）的地址，也可以表示已经被用户使用的数据块（不存在空闲链表中）的地址。

![img](https://uploadfiles.nowcoder.com/images/20190414/970829_1555246716341_19203EAD1152E0317EE9B5F6BFE090C6)
1、空间配置函数allocate
首先先要检查申请空间的大小，如果大于128字节就调用第一级配置器，小于128字节就检查对应的空闲链表，如果该空闲链表中有可用数据块，则直接拿来用（拿取空闲链表中的第一个可用数据块，然后把该空闲链表的地址设置为该数据块指向的下一个地址），如果没有可用数据块，则调用refill重新填充空间。
2、空间释放函数deallocate
首先先要检查释放数据块的大小，如果大于128字节就调用第一级配置器，小于128字节则根据数据块的大小来判断回收后的空间会被插入到哪个空闲链表。
3、重新填充空闲链表refill
在用allocate配置空间时，如果空闲链表中没有可用数据块，就会调用refill来重新填充空间，新的空间取自内存池。缺省取20个数据块，如果内存池空间不足，那么能取多少个节点就取多少个。
从内存池取空间给空闲链表用是chunk_alloc的工作，首先根据end_free-start_free来判断内存池中的剩余空间是否足以调出nobjs个大小为size的数据块出去，如果内存连一个数据块的空间都无法供应，需要用malloc取堆中申请内存。
假如山穷水尽，整个系统的堆空间都不够用了，malloc失败，那么chunk_alloc会从空闲链表中找是否有大的数据块，然后将该数据块的空间分给内存池（这个数据块会从链表中去除）。
3、总结：
\1. 使用allocate向内存池请求size大小的内存空间，如果需要请求的内存大小大于128bytes，直接使用malloc。
\2. 如果需要的内存大小小于128bytes，allocate根据size找到最适合的自由链表。
a. 如果链表不为空，返回第一个node，链表头改为第二个node。
b. 如果链表为空，使用blockAlloc请求分配node。
x. 如果内存池中有大于一个node的空间，分配竟可能多的node(但是最多20个)，将一个node返回，其他的node添加到链表中。
y. 如果内存池只有一个node的空间，直接返回给用户。
z. 若果如果连一个node都没有，再次向操作系统请求分配内存。
①分配成功，再次进行b过程。
②分配失败，循环各个自由链表，寻找空间。
I. 找到空间，再次进行过程b。
II. 找不到空间，抛出异常。
\3. 用户调用deallocate释放内存空间，如果要求释放的内存空间大于128bytes，直接调用free。
\4. 否则按照其大小找到合适的自由链表，并将其插入。

## 请你说说select，epoll的区别，原理，性能，限制都说一说

1）IO多路复用

IO复用模型在阻塞IO模型上多了一个select函数，select函数有一个参数是文件描述符集合，意思就是对这些的文件描述符进行循环监听，当某个文件描述符就绪的时候，就对这个文件描述符进行处理。

这种IO模型是属于阻塞的IO。但是由于它可以对多个文件描述符进行阻塞监听，所以它的效率比阻塞IO模型高效。



![img](https://uploadfiles.nowcoder.com/images/20190315/826546_1552638064152_94DD1FAB6C2E289FF496A8013E092EA5)

IO多路复用就是我们说的select，poll，epoll。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。

所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。

I/O多路复用和阻塞I/O其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。

所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）

在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。

2、select

select：是最初解决IO阻塞问题的方法。用结构体fd_set来告诉内核监听多个文件描述符，该结构体被称为描述符集。由数组来维持哪些描述符被置位了。对结构体的操作封装在三个宏定义中。通过轮寻来查找是否有描述符要被处理。

存在的问题：

\1. 内置数组的形式使得select的最大文件数受限与FD_SIZE；

\2. 每次调用select前都要重新初始化描述符集，将fd从用户态拷贝到内核态，每次调用select后，都需要将fd从内核态拷贝到用户态；

\3. 轮寻排查当文件描述符个数很多时，效率很低；

3、poll

poll：通过一个可变长度的数组解决了select文件描述符受限的问题。数组中元素是结构体，该结构体保存描述符的信息，每增加一个文件描述符就向数组中加入一个结构体，结构体只需要拷贝一次到内核态。poll解决了select重复初始化的问题。轮寻排查的问题未解决。

4、epoll

epoll：轮寻排查所有文件描述符的效率不高，使服务器并发能力受限。因此，epoll采用只返回状态发生变化的文件描述符，便解决了轮寻的瓶颈。

epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式

\1. LT模式

LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。

\2. ET模式

ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)



ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

3、LT模式与ET模式的区别如下：

LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

## C++11新特性———————>看其他总结

## C++构造函数抛异常会出现什么问题

1.构造函数中抛出异常将导致对象的析构函数不被执行

2.构造函数抛出异常可能导致内存泄露

## struct大小问题---内存对齐

对齐规则：

1、第一个成员的首地址为0.

2、每个成员的首地址是自身大小的整数倍

3、结构体的总大小，为其成员中所含最大类型的整数倍。

简单计算方法：

- **步骤一：前面单元的大小必须是后面单元大小的整数倍，如果不是就补齐**
- **步骤二：整个结构体的大小必须是最大字节的整数倍**

```c++
struct a{
    int b;
    char c;
    char d;
};//sizeof(a)是8
struct a1{
    char b1;
    int c1;
    char d1;
};//sizeof(a1)是12
struct a2{
    char a;
    char b;
    int c;
};//sizeof(a2)是8
```

## static和mutable

mutable不能修饰const数据成员容易理解，因为mutable与const本是反义，同时修饰不是自相矛盾吗。mutable不能修饰static数据成员，因为static数据成员存储在Data段或BSS段，属于类，不属于类对象，那么常对象和常函数可以对其任意地修改，所以类的static数据成员根本不需要mutable的修饰，但对于常对象的数据成员则不可以被修改，若想修改，则需要mutable的修饰

# 计算机网络

### TCP协议怎么保证有效传输

1.确认和重传2.数据校验3.流量控制4.拥塞控制

### TCP有哪几种关闭的情况

两种：一种是正常关闭的情况，另一种是收到RST后非正常关闭，，因为TCP作为可靠协议应该把数据发送完再处理，非正常关闭的话直接把发送缓冲区中的内容清空



# 数据库

### 请你说说MySQL的ACID特性分别是怎么实现的？

原子性 一致性 隔离性 持久性

# 操作系统

### 中断

硬中断就是外部设备（比如IO，时钟设备）的中断，软中断就是INT指令，异常就是CPU内部的中断，比如除零异常（大致可以这么理解？？？）

### 内核线程

kthread_creat() + wake_up_process) = kthread_run()

kthread_create()会调用create_kthread()进行创建线程，内部调用的是do_fork()

退出内核线程的话：1.主动退出，使用do_exit() 2.可以其他线程使用kthread_stop(线程名)进行杀死，但是被杀死的内核线程必须有kthread_should_stop获取信号，如果没有这个，它将不会获取其他线程的信号，不会被退出。

创建内核线程：

•声明一个task_struct结构体

•创建并初始化kthread_create_info结构体

•将kthrea_create_info结构体挂载到kthread_create_list链表上

•调用wake_up_process函数，启动kthreadd线程

•遍历链表，取出kthread_create_info结构体，创建内核线程

•初始化task_struct结构体

### do_fork

copy_mm可以分为3钟情况：

1 如果是内核线程，mm指针为null，直接退出，每次调度到内核线程时，会借用上一个进程的mm结构，放在active_mm中

2 如果不是内核线程，并且设置了CLONE_VM flag,则说明是个用户线程，共享父进程的运行空间，所以把父进程的mm赋值给子线程

3 如果以上情况都不是，那么新建的肯定是个进程，有独立的运行空间，所以需要新建自己的mm_struct结构，linux基于写时复制的原则，先复制父进程的页表。

### 使用epoll时注意什么

需要注意的是，当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

### 信号和信号量

**信号：（**signal）是一种处理异步事件的方式，**信号量：（**Semaphore）进程间通信处理同步互斥的机制

### CAS和信号量

比较并交换(compare and swap，CAS)，是原⼦操作的⼀种，可⽤于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某⼀数据时由于执行顺序不确定性以及中断的不可预知性产⽣的数据不一致问题



信号量和锁都必须依赖原子操作，也就是说原子操作可以用来实现信号量（信号量的加减都必须是原子的），也可以用来实现锁（包括一般的加锁，自旋锁，读写锁等），补充最后一句：不同的处理器（intel、arm），不同的架构（单核、多核）实现原子操作的方式不一样，有的是通过加锁封锁总线，有的是做成单指令，有的是依据标志位，有的是依据cpu相关的指令对，总之不同的机制可以实现原子操作，有性能上的区别，再依据原子操作，从而封装除了信号量，锁等机制，用于不同的代码需求。

### linux启动过程

1.系统上电自检

2.bootloader，启动Bootloader指令地址（ARM结构的cpu一般放在0x0000000地址处，而MIPS结构的CPU一般放在0xBFC00000），，，Bootloader是嵌入式系统的引导加载程序，它是系统上电后运行的第一段程序，其作用类似于 PC 机上的 BIOS。在完成对系统的初始化任务之后，它会将非易失性存储器（通常是Flash或DOC等）中的Linux 内核拷贝到 RAM 中去，然后跳转到内核的第一条指令处继续执行，从而启动 Linux 内核。，，，，会完成硬件初始化（看门狗、RAM初始化等）、检查系统内存映射、为内核启动设置参数

3.启动内核，，，，对于ARM 系列处理器来说，zImage 的入口程序即为 arch/arm/boot/compressed/head.S。它依次完成以下工作：开启 MMU 和 Cache，调用 decompress_kernel()解压内核，最后通过调用 call_kernel()进入非压缩内核 Image 的启动。下面将具体分析在此之后 Linux 内核的启动过程

start_kernel函数，start_kernel是所有 Linux 平台进入系统内核初始化后的入口函数，它主要完成剩余的与硬件平台相关的初始化工作，在进行一系列与内核相关的初始化后，调用第一个用户进程－init 进程并等待用户进程的执行，这样整个 Linux 内核便启动完毕

### bootloader和bootrom

Bootloader负责查找和加载应该在芯片上运行的最终操作系统或固件。与bootrom的一个主要区别是它通常在可写闪存中，可以更换或升级。

有时bootrom可以执行引导加载程序的工作。例如，OMAP的bootrom足够复杂（它可以解析FAT32！），你可以加载它并直接启动Linux内核。

但是，在许多情况下，使用单独的引导加载程序，或者因为bootrom不够（或不存在），或者因为需要额外的灵活性。它可以非常简单（从RAM中的固定闪存位置加载内核并跳转到它），或者可能更复杂。例如， 的U-Boot 就像一个迷你操作系统本身 - 它有一个控制台，一些命令，允许你打破启动过程，例如修改内核命令行参数，甚至从不同的位置（SD / MMC或USB）加载内核，运行一些测试等等

# linux内核

### 内存管理概述

用户空间中，应用程序通过malloc和free申请释放内存，malloc和free是glic库的内存分配器ptmalloc提供的接口，ptmalloc通过使用系统调用brk或mmap向内核以页为单位申请内存，然后划分成小内存块分配给应用程序

内核空间中，sys_brk用来扩大和收缩堆，sys_mmap在内存映射区域分配虚拟页，sys_munmap用来释放虚拟页

延迟分配策略，

页分配器分配物理页，当前使用的页分配器是伙伴分配器

内核空间提供了把页划分成小内存块分配的块分配器，提供分配内存的接口kmalloc和释放内存的接口kfree，支持三种快分配器SLAB、SLUB和SLOB

**伙伴分配器是页分配器，用来分配物理页，而把页划分成更小的块用的是块分配器，有SLAB、SLUB和SLOB**

内核初始化时，页分配器还没有准备好，需要使用临时的引导内存分配器分配内存

![内存管理](md相关图片/内存管理.png)

在进程的虚拟地址空间中，代码段和数据段是私有的文件映射，未初始化数据段、堆和栈都是私有的匿名映射

![内存映射原理](md相关图片/内存映射原理.png)

![文件映射的内存区域](md相关图片/文件映射的内存区域.png)

![虚拟内存区域的链表和树](md相关图片/虚拟内存区域的链表和树.png)

![备用区域列表](md相关图片/备用区域列表.png)

### 内核空间动态布局

4G大小下，内核空间是1G，前896M是直接映射区，映射特别重要的数据结构，如task_struct、内核栈等，这896M直接映射到物理内存的前896M--------------vmalloc区，内核动态映射区，像用户态可以使用malloc一样，内核可以使用vmalloc在这区域映射物理内存-------------------持久映射区，映射页表等不经常发生变动的数据结构--------------------固定映射区用于满足特殊需要-------------------最上面空白部分用于临时内核映射，如将文件向用户态映射时，需要内核协助(因为有IO)，故需要一段映射区用于中转到用户映射好的物理内存，使用完毕释放即可

### current宏

使用current宏可以获取当前进程的task_struct结构体

ARM64中：通过sp_el0寄存器得到task_struct结构体的地址

ARM32中：通过thread_info得到task_struct结构体，想想那三个数据结构的图，thread_info是和内核栈在一起的，所以内核栈是可以找到的，这样thread_info的位置其实也是确定的（**对内核栈的栈指针进行一下内存对齐**），故可以找到

### NUMA

非统一内存访问方式

以前的访问方式是SMP组织形式，就是多个核心平等的对内存进行访问

NUMA访问方式使物理内存的页面变得不连续了，内存模型变成了非连续内存模型，，每个CPU与一个本地内存的节点叫做NUMA节点，，，这感觉就像是把内存给瓜分了？？？一个CPU管着一片内存？

当采取NUMA方式利用内存时有多个CPU就有多个NUMA节点，而每一个NUMA节点又由多个区域组成，每个区域负责管理自己范围内的页面。当系统要求分配大块(即多页)内存时使用伙伴系统分配，而像使用malloc这样分配小块内存会使用slab分配器进行分配。，，，**大块伙伴分配器，小块块分配器，SLAB**

每个NUMA节点由很多zone组成，zone用struct zone来描述

### page结构体

里面包含很多union结构体，是因为一个页面可以用作多个模式。

有指示用于匿名页映射或文件页映射的union，还有指示用于分配小块内存的slab的union

### 伙伴系统

有个结构体：

```C++
#define MAX_ORDER 11
struct free_area free_area[MAX_ORDER];//负责管理当前区域空闲块的数组，最大为11，是11个页块链表，每个块链表分别包含1，2，4，8，。。。个连续页的页块   2的i次方，这个i叫做阶
//其具体实现逻辑就是你要多少页块内核就按这个大小朝上取整至符合11个页块链表中页块大小的一个标准值分配之，若没有就继续取更大的块
```

伙伴系统核心函数是核心函数__alloc_pages_nodemask，它是核心方法最终会调用get_page_from_freelist函数寻找空闲块，在该函数内就执行一系列的流程函数最终找到合适的块并从当前链表移除，若有多余部分则挂在前面的块链表上

*如果合并成n+1阶块，那么第一页的物理号必须是2的n+1次方的整数倍*故0和1是伙伴，2和3是伙伴，1和2不是伙伴，因为12组成的起始不是2的1次方

分配：如果分配n阶块，先到空闲链表去找，找到的话就分配。找不到就到n+1阶去找合适的，找到合适的，就分裂，一个分配出去，一个插入n阶空闲链表，n+1阶也没有合适的，就去n+2阶找

释放：看它的伙伴是否空闲，若不空闲，将当前块插入空闲链表，，若空闲，那么将这两个伙伴进行合并，合并成n+1阶块，然后释放n+1阶块

### fork

fork创建进程，从系统调用表sys_call_table查找之后调用系统调用sys_fork，sys_fork又调用do_fork，主要做两件事情，复制父进程的task_struct结构体，唤醒新创建的线程

do_fork中copy_process是复制进程，wake_up_new_task是唤醒

copy_process底层调用dup_task_struct复制task_struct对象，dup_task_struct调用alloc_task_struct_node分配为task_struct结构分配内存，继续向下走发现它调用kmem_cache_alloc_node函数系统初始化时会为我们创建一个叫做task_struct_cachep的缓冲区，这个缓冲区里面都是一个个的大小刚好等于task_struct结构体大小的内存块，即每一个task_struct结构块的大小为arch_task_struct_size。
故有了这样一个机制之后我们每次为新的进程分配内存时就调用kmem_cache_alloc_node在这个缓冲区里面去找，当进程结束调用free_task_struct释放task_struct结构体时也是调用kmem_cache_free函数直接放回这个缓冲区即可，并不真正的去内存申请

### kswapd 负责物理页面的换入换出

### struct  kmem_cache

虽然是小块内存分配，其实就是将这个缓存维护的大块内存分为一个个的小块交给相关的数据结构去使用。当内核申请分配小块缓存时会先从kmem_cache_cpu快速分配，若分配失败则从kmem_cache_node中分配然后挂在到free。。。的链表上继续，最后实在不行就去伙伴系统分配大块至当前缓冲区然后重新分配。

![kmem_cache_node](md相关图片/kmem_cache_node.png)

### 页面换出

分匿名页和文件，对于被回收的匿名页，需要分配swap，将内存页写入文件系统；对于内存映射的页面会将对文件的修改写回到文件中

### 大文件映射mmap（注意注意注意！！！并不分配物理页，只分配虚拟地址空间）

要考虑到两种情况：**(1)匿名映射，即虚拟内存与物理内存的映射; (2)文件与虚拟内存的映射**

首先sys_mmap调用sys_mmap_pgoff，函数首先判断若是匿名文件直接调用vm_mmap_pgoff完成映射，否则先获得映射文件的struct file结构然后调用vm_mmap_pgoff完成映射，而vm_mmap_pgoff函数经过一系列数据处理与函数调用最终会调用do_mmap函数，该函数中get_unmapped_area用于找到虚拟内存中目前还未映射的内存空间，而无论是对于匿名映射还是文件映射其实他们的本质就是在mm_struct的管理各虚拟区域数据结构的红黑树中找到在内存映射区中的最靠近vm_area_struct然后返回地址

### 缺页中断

![页错误处理异常情况](md相关图片/页错误处理异常情况.png)

![ARM64处理页错误异常](md相关图片/ARM64处理页错误异常.png)

触发缺页中断，调用回调函数do_page_fault。
而do_page_fault函数其实做的事情也比较简单，它首先会根据触发缺页中断的虚拟地址创建此虚拟地址对应的页表项，就拿64bit的操作系统来说的话它就会创建上层页目录表项PUD与中层页目录表项PMD以及最后一层的页表项。而对页表项绑定具体的物理地址的时候要分三种情况：（*获取出错的页面的虚拟地址，X86通过CR2寄存器，ARM64存到了FAR寄存器，然后还有一个esr，指向了fault_info结构体，存储的错误的其他信息*）
(1)匿名映射，直接利用伙伴系统分配新的页即可
(2)文件内存映射，若有缓存页就找到安排之，否则将文件读入内存
(3)页面被换出到swap区，即磁盘上了

__do_page_fault首先判断缺页异常发现的空间是内核还是用户空间，如果说是内核的话就调用vmalloc_fault(address)函数处理之

当发生在用户空间的时候先调用find_vma函数找到发生异常地址对应的虚拟地址存储区对应的vm_area_struct结构，然后调用handle_mm_fault——>`__handle_mm_fault(vma, address, flags)`处理这个缺页异常，函数先构造了对应的PUD与PMD两级页目录项，然后调用handle_pte_fault函数去构造页表项，以及使用具体的物理页面的物理地址初始化这个新的页表项

当对应的页表项不存在时它会分三种处理：

1.*当为匿名映射时调用vma_is_anonymous*
vma_is_anonymous函数分配页表项，同时在伙伴系统上分配物理页面初始页表项，最后将页表项插到页表上。

2.*do_fault处理文件映射*
do_fault最终会调用__do_fault函数：若内存中有文件缓存就将缓存找到，如果不在就会申请一个事先准备好的缓存页然后调用相关函数将文件从磁盘上读到内存里面就可以了。对*第二种情况要特别注意，内核并不能直接将文件内容直接放到用户空间映射的物理页面上，因为内核不能使用物理地址，所以就需要在内核里面临时映射一把，这就是在前面剖析内核空间布局时关于最上面临时映射区的具体使用途径*

3.*swap缓冲区*
`do_swap_page(vmf)`
前面了解过有一个内核线程Kswapd会将长时间不在使用的物理页面换出内存到swap区，此处针对的就是这种情况，他会先在swap缓冲区中查找是否有我们要查找的页面，有就好，没有的话就会重新分配页面将swap区数据给读取进来

*总结：*

*当调用mmap函数进行用户态内存映射时仅仅只是先分配虚拟内存，当真正使用时才会分配*
*当发生缺页中断时调用回调函数do_page_fault，该函数会根据触发缺页中断的虚拟地址创建此虚拟地址对应的页表项PUD与PMD以及最后一层的页表项。最后当为匿名映射，直接利用伙伴系统分配新的物理内存；为文件映射时将文件读入内存；如果是swap就将swap读入。*
*对于每一个进程来说当在用户态时他们进行物理地址的转换时并不需要进入内核态，因为有一个CPU寄存器Cr3（arm中是ttbr0）里面保存了当前进程的顶级页表gpd,它可以自动将虚拟地址转换为物理地址，只有当初发缺页中断时才会调用do_page_fault进入内核态*
*最后最后，在进行虚实地址转换时为了更进一步提高映射速度又提出了快表机制以便于更快的查询。其实本质上就是利用局部性原理将经常要访问的那些页表部分给缓存到TLB这个硬件中罢了，只是这种硬件设备除了速度比内存更快之外，容量也很小。*

### 用户态和内核态的顶级页表

用户态：pgd_t* pgd在mm_struct中

内核态：系统初始化时进行了定义，swapper_pg_dir，内核也有自己的mm_struct结构体

### vmalloc函数与kmap_atomic的区别

对于kmap_atomic发现没有页表的时候会直接创建页表进行映射，而vmalloc则和mmap一样只是分配虚拟地址，所以会发生缺页异常，然后调用do_page_fault处理之。

### page结构体

内核使用page结构体描述一个物理页，内存的所有物理页对应一个page结构体数组，，，存在于内核vmemmap区

### KASAN影子区域

动态内存错误检查工具，为发现释放后使用和越界访问这两类缺陷提供了快速和综合的解决方案

### 页缓存

Linux 内核使用 `页缓存（Page Cache）` 机制来对文件中的数据进行缓存。为了提升对文件的读写效率，Linux 内核会以页大小（4KB）为单位，将文件划分为多数据块。当用户对文件中的某个数据块进行读写操作时，内核首先会申请一个内存页（称为 `页缓存`）与文件中的数据块进行绑定

![页缓存](md相关图片/页缓存.png)

- 当从文件中读取数据时，如果要读取的数据所在的页缓存已经存在，那么就直接把页缓存的数据拷贝给用户即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把页缓存的数据拷贝给用户。

- 当向文件中写入数据时，如果要写入的数据所在的页缓存已经存在，那么直接把新数据写入到页缓存即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把新数据写入到页缓存中。对于被修改的页缓存，内核会定时把这些页缓存刷新到文件中

  *？？？？所以这个缓存页就是在上面说的临时映射区？？？？*

### address space

 Linux 内核中，使用 `file` 对象来描述一个被打开的文件，其中有个名为 `f_mapping` 的字段，`f_mapping` 字段的类型为 `address_space` 结构，其定义如下：

```c++
struct address_space {
    struct inode           *host;      /* owner: inode, block_device *///指向当前 address_space 对象所属的文件 inode 对象（每个文件都使用一个 inode 对象表示）
    struct radix_tree_root page_tree;  /* radix tree of all pages *///用于存储当前文件的 页缓存，，，，文件的 页缓存 使用了 radix树 来存储。radix树：又名基数树，它使用键值（key-value）对的形式来保存数据，并且可以通过键快速查找到其对应的值。内核以文件读写操作中的数据 偏移量 作为键，以数据偏移量所在的 页缓存 作为值，存储在 address_space 结构的 page_tree 字段中
    rwlock_t               tree_lock;  /* and rwlock protecting it *///用于防止并发访问 page_tree 导致的资源竞争问题
    ...
};//address_space 结构其中的一个作用就是用于存储文件的 页缓存
```

页缓存中的页是通过地址空间（address_space）来和物理设备内存（如底层文件系统的struct inode结构）相互关联的。对应与page结构的struct address_space *mapping成员。
（1）       如果page->mapping等 于0，说明该页属于交换告诉缓存swap cache
（2）       如果page->mapping不 等于0，但第0位为0，说明该页为匿名也，此时mapping指向一个struct anon_vma结构变量；
（3）       如果page->mapping不 等于0，但第0位不为0，则apping指向一个struct address_space地址空间结构变量

### 写时复制

情况：1：父进程fork子进程，写只读页，没有权限，会分配一个新物理页，把那个物理页的数据复制到新的物理页2：进程创建私有的文件映射，然后读访问，触发页错误异常，异常处理程序把文件读到**页缓存**，然后以只读模式把虚拟页映射到文件的页缓存中的物理页。接着执行写访问，触发页错误异常，异常处理程序执行写时复制，为文件的页缓存中的物理页创建一个副本，把虚拟页映射到副本。这个副本是进程的私有匿名页，和文件脱离关系，修改副本不会导致文件变化

### 内存管理子系统使用节点（NUMA节点？？）、区域（zone）、页三级结构描述物理内存

### BIOS和bootloader

BIOS 在完成硬件检测和资源分配后，将硬盘MBR中的 Boot Loader 读到系统的RAM 中，然后将控制权交给 OS Boot Loader。Boot Loader 的主要运行任务就是将内核映象从硬盘上读到RAM 中，然后跳转到内核的入口点去运行，也即开始启动操作系统

bootloader的作用：初始化硬件设备、建立内存空间的映射图

Boot Loader 的 stage1 通常包括以下步骤(以执行的先后顺序)：
·硬件设备初始化。
·为加载 Boot Loader 的 stage2 准备 RAM 空间。
·拷贝 Boot Loader 的 stage2 到 RAM 空间中。
·设置好堆栈。
·跳转到 stage2 的 C 入口点。
Boot Loader 的 stage2 通常包括以下步骤(以执行的先后顺序)：
·初始化本阶段要使用到的硬件设备。
·检测系统内存映射(memory map)。
·将 kernel 映像和根文件系统映像从 flash 上读到 RAM 空间中。
·为内核设置启动参数。
·调用内核。



BIOS，Basic Input Output System 基本输入输出系统，意思是主板级别的一个小系统。负责系统（主要是主板）的硬件初始化，例如CPU，内存，硬盘，键盘，显示卡，网卡等等硬件的初始化。初始化是BIOS的主要工作。传统的个人电脑上面BIOS会有一个int19 软件中断功能，在初始化完成后，BIOS会进入int19中断，寻找启动介质，如软盘，光盘，硬盘，flash或者网络等等，读取第一个扇区的内容到内存的0000:7C00处，跳入这个地址执行。这里int19就是一个bootloader，启动引导器。所以BIOS具有Boot Loader的功能。当然，目前的BIOS功能已经被扩充了很多，例如电源管理方面的ACPI接口，USB驱动，PXE网络引导功能，硬盘加密，TPM接口，BIOS配置界面，BIOS自动恢复等等。

不过目前的Boot Loader功能也并不单纯，例如u-boot，一个有名的开源boot loader，其实还是会做一小部分硬件初始化的工作，主要用在嵌入式系统。

### page cache和buffer cache

Page cache 也叫页缓冲或文件缓冲，是由好几个磁盘块构成，大小通常为4k，在64位系统上为8k，构成的几个磁盘块在物理磁盘上不一定连续，文件的组织单位为一页， 也就是一个page cache大小，文件读取是由外存上不连续的几个磁盘块，到buffer cache，然后组成page cache，然后供给应用程序。---------------------------**所以page cache相当于在 buffer cache的上层？？**

Page cache在linux读写文件时，它用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问。具体说是加速对文件内容的访问，buffer cache缓存文件的具体内容——物理磁盘上的磁盘块，这是加速对磁盘的访问。

磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。

假设我们通过文件系统操作文件，那么文件将被缓存到Page Cache，如果需要刷新文件的时候，Page Cache将交给Buffer Cache去完成，因为Buffer Cache就是缓存磁盘块的。

也就是说，直接去操作文件，那就是Page Cache区缓存，用dd等命令直接操作磁盘块，就是Buffer Cache缓存的东西。

**页缓存中的页在物理内存上是连续的，在磁盘上不一定，是由很多磁盘块构成的，所以分了cache和buffer？？？**

# 项目

# 面试时，凡是牵扯到数据量相当大的问题，都可以向hash靠拢？？？



# 新开

### 自旋锁相关

**单处理器自旋锁的工作流程是**:单处理器中自旋锁不被启用，因为使用自旋锁的中断执行路径一旦被嵌套可能会造成永久等待，同步途径是关闭内核抢占->运行临界区代码->开启内核抢占。更加安全的单处理器自旋锁工作流程是:保存IF寄存器->关闭当前CPU中断->关闭内核抢占->运行临界区代码->开启内核抢占->开启当前CPU中断->恢复IF寄存器。

**多处理器自旋锁的工作流程是**：关闭内核抢占->（忙等待->)获取自旋锁->运行临界区代码->释放自旋锁->开启内核抢占。更加安全的多处理器自旋锁工作流程是：保存IF寄存器->关闭当前CPU中断->关闭内核抢占->（忙等待->)获取自旋锁->运行临界区代码->释放自旋锁->开启内核抢占->开启当前CPU中断->恢复IF寄存器。